# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iOXF-m5mVlQ740blqPEbf2-zYwpTIP3V
"""

from flask import Flask, render_template, request,jsonify
import pickle
import librosa
from tensorflow.keras.models import Model
import tensorflow as tf
import numpy as np
import pandas as pd 
import io

app = Flask(__name__)

def preprocessing(audio_data):
  max_len=15*16000
  data,sr=librosa.load(audio_data,sr=16000)
  data, _ = librosa.effects.trim(data, top_db=60)

  if len(data)>max_len:
    # selecting random subsample from data of length= max_len
    max_offset = len(data) - max_len
    offset = np.random.randint(max_offset+1)
    data = data[offset:(max_len+offset)]
      
  elif len(data)<max_len:    
    #padding with zero with       
    data = np.pad(data, (0, max_len-len(data)), "constant") 

  data=librosa.feature.mfcc(y=data, sr = 16000, n_mfcc=40)

  data=data[np.newaxis,:,:,np.newaxis]
  #predictions=model.predict(data,verbose=0)
  return data

@app.route('/')
def hello_world():
    return 'Hello World!'

@app.route('/predict', methods=['POST'])
def predict():

    model=tf.keras.models.load_model('mfcc_best.h5')
    labels_list=pickle.load(open('labels_list.pkl', 'rb'))
    # Read the audio file
    audio_file = request.files['audio']
    data=preprocessing(audio_file)

    
    
    # Make a prediction using the model
    predictions=model.predict(data,verbose=0)

    pred_labels=[]
    for i,ele in enumerate(predictions[0]):
      if ele>0.5:            
        pred_labels.append(labels_list[i])
    if len(pred_labels)<1:
      i=np.argmax(predictions[0])
      pred_labels.append(labels_list[i])
    


    # Return the prediction
    return jsonify({'prediction': str(pred_labels)})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)